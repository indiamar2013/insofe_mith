---
title: "Amar Rao Batch35_Mith"
author: "Amar Rao"
date: "January 6, 2018"
output: 
  html_document:
  toc: true
  toc_float:
  collapsed: false
  theme: united
  highlight: tang
  fig_width: 7
  fig_height: 6
  fig_caption: true
  code_folding: hide

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all = TRUE))

```

```{r}
library(data.table)
library(caret)

```


```{r}
setwd('/home/amar/insofe_mith')

#load the train and test data

train <- fread('Train.csv', sep = ',', na.strings = c('NA', '?', ''), stringsAsFactors = T)
test <- fread('Test.csv', sep = ',', na.strings = c('NA', '?', ''), stringsAsFactors = T)

```


#Initial submission - simple mean. We cannot do worse than this so this will be the
# floor/low water mark
```{r}
test$HomeAssetValue <- mean(train$HomeAssetValue)
predictions <- data.frame(ID = test$ID, HomeAssetValue = test$HomeAssetValue)
write.csv(x = predictions, file = 'predictions.csv', row.names = FALSE)
test$HomeAssetValue <- NULL

```

* This got a MAPE of 37% on Grader.




```{r}

head(train)
summary(train)
str(train)



```

##Observations

* Region - most of the data is for homes in one region (RL). Will be interesting to see the difference in home prices in other regions
* Proximity and Proximity2 - most of the data is for Norm proximity, need to see if home prices are different for other proximities
* The data is for Maharashtra, there are 10 that are NAs - will remove them
* CompoundWallQuality has unusually large number of NAs... this could indicate a hidden trend.
* PoolQuality is also missing a very large number of values... Same as compound wall quality
* ConstructionYear - the oldest house is from 1875 - will engineer a feature to use age of house instead of construction year
* RemodelYear - instead of using the year, will have a feature to compute years since remodel
* Country - India - 10 are missing this - will remove those rows
* ConditionOfSale - need to see how the home price varies with this variable
* GardenAccessPathType also has very large number of NAs
* YearOfSale - this shows when the house was last sold?
* CarParkingStartYear - has a -1 - need to check that. Again, will compute age as a feature
* Month of Sale is already available. Should be interesting to see if there's seasonality
* OverallCondition is actually a rank variable.
* ValueOfMisc variable seems to be suspicious. should see if this is needed
* Should see how HomeStyle, GardenExposure, affects Price

###Columns that might not make much of a difference given most observations have one value

* PavedDriveway (most of the columns is Y)
* ValueOfMisc
* CarParkingAreaCondition
* FunctionalityRating (most are Typ)
* HeaterMechanismType (most are GasA)
* CellarCondition (Most are TA)
* Electrical (most are SBrkr)
* ExteriorMaterialCondition
* Utilities
* CarParkingQuality
* ACType

###Columns that have >13000 NA values

* Miscellaneous
* PoolQuality
* CompoundWallQuality
* GardenAccessPathType

**All the above mentioned columns are categorical.  **


** checking to see if these are true with test data as well

```{r}
summary(test)

```

** Test data also shows that the highlighted columns have a similar distribution.

##Exploratory Data Analysis

* Home Price by Region


```{r}

require(ggpubr)

region_box <- ggplot(train, aes(group = Region, color = Region)) +
  geom_boxplot(mapping = aes(x = Region, y = HomeAssetValue))
  
region_hist <- ggplot(train) +
  geom_bar(mapping = aes(x = Region, fill = Region))

ggarrange(region_box, region_hist, nrow=2, ncol=1)

```

**Observation: the RL region accounts for most of the home values but the prices in this region also vary the most. We can think of two models one for RL and other for the rest and combine for predictions.**

**Proximity1 and Proximity 2**

```{r}


prox1_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = Proximity1, y = HomeAssetValue, group = Proximity1, color = Proximity1))

prox1_hist <- ggplot(train) +
  geom_bar(mapping = aes(x = Proximity1, fill = Proximity1))

prox2_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = Proximity2, y = HomeAssetValue, group = Proximity2, color = Proximity2))

prox2_hist <- ggplot(train) +
  geom_bar(mapping = aes(x = Proximity2, fill = Proximity2))

ggarrange(prox1_box, prox2_box, prox1_hist, prox2_hist)

```


** Normal proximity is heavily playing in the home asset value although the mean is the same as most of the other proximities
so 

```{r}

region_proximity1 <- ggplot(train) +
  geom_bar(mapping = aes(x = Region, group = Proximity1, fill = Proximity1))
region_proximity2 <- ggplot(train) +
  geom_bar(mapping = aes(x = Region, group = Proximity2, fill = Proximity2))

ggarrange(region_proximity1, region_proximity2)

```


** The combination of Region = RL, Proximity1 = Normal, Proximity2 = Normal should be modeled separately. I will do that after creating a few models as is**


** Visualizing how homestyle affects HomeAssetValue **

```{r}

homestyle_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = HomeStyle, y = HomeAssetValue, color=HomeStyle))
homestyle_hist <- ggplot(train) +
  geom_bar(mapping = aes(x=HomeStyle, fill = HomeStyle))

ggarrange(homestyle_box, homestyle_hist +rremove("x.text"), nrow=2, ncol=1)

```

** 1-story and 2-story houses make up the bulk of the sales. However the mean price doesn't seem to vary significantly from other types of homes**


```{r}

garden_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = GardenExposure, y = HomeAssetValue, color=GardenExposure))
garden_hist <- ggplot(train) +
  geom_bar(mapping = aes(x=GardenExposure, fill = GardenExposure))

ggarrange(garden_box, garden_hist +rremove("x.text"), nrow=2, ncol=1)

```

** GardenExposure has no impact on the median HomeAssetValue **

```{r}

condtype_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = ConditionOfSale, y = HomeAssetValue, color=ConditionOfSale))
condtype_hist <- ggplot(train) +
  geom_bar(mapping = aes(x=ConditionOfSale, fill = ConditionOfSale))

saletype_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = TypeOfSale, y = HomeAssetValue, color=TypeOfSale))
saletype_hist <- ggplot(train) +
  geom_bar(mapping = aes(x=TypeOfSale, fill = TypeOfSale))

ggarrange(condtype_box, saletype_box, condtype_hist, saletype_hist +rremove("x.text"))

```


```{r}
hometype_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = HomeType, y = HomeAssetValue, color=HomeType))
hometype_hist <- ggplot(train) +
  geom_bar(mapping = aes(x=HomeType, fill = HomeType))

ggarrange(hometype_box, hometype_hist +rremove("x.text"), nrow=2, ncol=1)


```



###Treating NAs for country and state

* There are exactly 10 values in the training data set that do not have country/state specified. 
* Checking if their central tendencies are significantly different. If no, will remove, if not, will have to treat them separately

```{r}
country_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = Country, y = HomeAssetValue, color=Country))

state_box <- ggplot(train) +
  geom_boxplot(mapping = aes(x = State, y = HomeAssetValue, color = State))

ggarrange(country_box, state_box, nrow=2, ncol = 1)
```


** there's not much of difference so will just impute these to be India and Maharashtra respectively

```{r}

train$Country <- ifelse(is.na(train$Country), "INDIA", levels(train$Country))
table(train$Country)
sum(is.na(train$Country))
train$State <- ifelse(is.na(train$State), "Maharashtra", levels(train$State))
table(train$State)
sum(is.na(train$State))

#doing the same with test data
test$Country <- ifelse(is.na(test$Country), "INDIA", levels(test$Country))
table(test$Country)
sum(is.na(test$Country))
test$State <- ifelse(is.na(test$State), "Maharashtra", levels(test$State))
table(test$State)
sum(is.na(test$State))


```


##Treating dates

* The following columns have date type:
ConstructionYear
RemodelYear
YearOfSale
CarParkingStartYear

* Will convert these into ages so that we can see how that impacts the sale price. If there's good correlation, will use their age when they were sold.


```{r}

sum(is.na(train$ConstructionYear))
sum(is.na(train$RemodelYear))
sum(is.na(train$YearOfSale))
sum(is.na(train$CarParkingStartYear))

#all four columns have data so will do a simple substraction

train[,ConstructionAge := YearOfSale - ConstructionYear]
train[,RemodelAge := YearOfSale - RemodelYear]
train[,CarParkStartAge := YearOfSale - CarParkingStartYear]

#Removing ConstructionYear, RemodelYear, and CarParkingStartYear
train$ConstructionYear <- NULL
train$RemodelYear <- NULL
train$CarParkingStartYear <- NULL

str(train)

#doing the same with test
test[,ConstructionAge := YearOfSale - ConstructionYear]
test[,RemodelAge := YearOfSale - RemodelYear]
test[,CarParkStartAge := YearOfSale - CarParkingStartYear]

#Removing ConstructionYear, RemodelYear, and CarParkingStartYear
test$ConstructionYear <- NULL
test$RemodelYear <- NULL
test$CarParkingStartYear <- NULL



const_age <- ggplot(train) +
  geom_point(mapping = aes(x = HomeAssetValue, y = ConstructionAge, color=Region))

remodel_age <- ggplot(train) +
  geom_point(mapping = aes(x = HomeAssetValue, y = RemodelAge, color=Region))

carpark_age <- ggplot(train) +
  geom_point(mapping = aes(x = HomeAssetValue, y = CarParkStartAge, color=Region))

ggarrange(const_age, remodel_age, carpark_age, nrow=3)

```




###Removing columns that have majority one factor

###Columns that might not make much of a difference given most observations have one value

* PavedDriveway (most of the columns is Y)
* ValueOfMisc
* CarParkingAreaCondition
* FunctionalityRating (most are Typ)
* HeaterMechanismType (most are GasA)
* CellarCondition (Most are TA)
* Electrical (most are SBrkr)
* ExteriorMaterialCondition
* Utilities
* CarParkingQuality
* ACType

###Columns that have >13000 NA values

* Miscellaneous
* PoolQuality
* CompoundWallQuality
* GardenAccessPathType

**All the above mentioned columns are categorical.  

```{r}
cols_to_exclude = c('PavedDriveway', 'ValueOfMisc', 'CarParkingAreaCondition', 'FunctionalityRating', 'HeaterMechanismType', 'CellarCondition', 'Electrical', 'ExteriorMaterialCondition', 'Utilities', 'CarParkingQuality', 'ACType')

na_cols_to_exclude = c('Miscellaneous', 'PoolQuality', 'CompoundWallQuality', 'GardenAccessPathType')

cptrain <- train

cptrain <- cptrain[, !cols_to_exclude, with=FALSE]
cptrain <- cptrain[, !na_cols_to_exclude, with=FALSE]

cptest <- test
cptest <- cptest[, !cols_to_exclude, with=FALSE]
cptest <- cptest[, !na_cols_to_exclude, with=FALSE]

cptrain$State <- as.factor(cptrain$State)
cptest$State <- as.factor(cptest$State)
cptrain$Country <- as.factor(cptrain$Country)
cptest$Country <- as.factor(cptest$Country)


```


#check if any other columns have NA that we have to treat differently

```{r}
sort(colSums(is.na(cptrain)), decreasing=TRUE)

```



```{r}
sort(colSums(is.na(cptrain)), decreasing=TRUE)

#AcsQuality, CellarFinishingQualityType2, InteriorCarParkingFinish, CarParkingType, TilingType,GardenExposure,CellarFinishingQualityType1,CellarQuality all have Nas.

getImputedValue <- function(vec) {
  freqVal <- names(sort(table(vec), decreasing=TRUE))[1]
  ret <- vec                         
  for (i in 1:length(vec)) {
    if(is.na(vec[i])) {
      ret[i] <- freqVal
    }
  }
  return(ret)
}

cptrain$AcsQuality <- getImputedValue(cptrain$AcsQuality)
cptrain$CellarFinishingQualityType2 <- getImputedValue(cptrain$CellarFinishingQualityType2)
cptrain$InteriorCarParkingFinish <- getImputedValue(cptrain$InteriorCarParkingFinish)
cptrain$CarParkingType <- getImputedValue(cptrain$CarParkingType)
cptrain$TilingType <- getImputedValue(cptrain$TilingType)
cptrain$GardenExposure <- getImputedValue(cptrain$GardenExposure)
cptrain$CellarFinishingQualityType1 <- getImputedValue(cptrain$CellarFinishingQualityType1)
cptrain$CellarQuality <- getImputedValue(cptrain$CellarQuality)

sum(is.na(cptrain))

```


* check the same with test data

```{r}

cptest$AcsQuality <- getImputedValue(cptest$AcsQuality)
cptest$InteriorCarParkingFinish <- getImputedValue(cptest$InteriorCarParkingFinish)
cptest$CarParkingType <- getImputedValue(cptest$CarParkingType)
cptest$CellarFinishingQualityType1 <- getImputedValue(cptest$CellarFinishingQualityType1)
cptest$CellarFinishingQualityType2 <- getImputedValue(cptest$CellarFinishingQualityType2)
cptest$GardenExposure <- getImputedValue(cptest$GardenExposure)
cptest$TilingType <- getImputedValue(cptest$TilingType)
cptest$CellarQuality <- getImputedValue(cptest$CellarQuality)

sum(is.na(cptest))
```


###Convert all factor columns into numeric by creating dummy variables

```{r}
library(dummies)
summary(cptrain)
summary(cptest)

#removing ID from train
rownames(cptrain) <- cptrain$ID
cptrain$ID <- NULL
rownames(cptest) <- cptest$ID
cptest$ID <- NULL

factorcols <- names(which(sapply(cptrain, class) == 'factor'))
numericcols <- names(which(sapply(cptrain, class) != 'factor'))
numericcols
dummified_train <- dummy.data.frame(cptrain, names = factorcols, sep = "_")
dummified_test <- dummy.data.frame(cptest, names = factorcols, sep = "_")

#there are a few columns missing in test that are in train - these are levels from categorical columns.
#remove those from train
missingcols <- setdiff(colnames(dummified_train), colnames(dummified_test))
missingcols

#of these HomeAssetValue is expected to be missing. the rest we have to exclude
missingcols <- missingcols[which(missingcols != 'HomeAssetValue')]

clean_train <- dummified_train[,!colnames(dummified_train) %in% missingcols]
clean_test <- dummified_test

```

#Center and scale numeric variables

```{r}
library(caret)

numericcols
numeric_x <- numericcols[which(numericcols != 'HomeAssetValue')]
numeric_x
preproc_preds <- preProcess(x = clean_train[,colnames(clean_train) %in% numeric_x], method = c("center", "scale"))
clean_train <- predict(preproc_preds, clean_train)
clean_test <- predict(preproc_preds, clean_test)

ncol(clean_train)
ncol(clean_test)



```

###Splitting train set into train and validation
```{r}
train_rows <- sample(x = 1:nrow(clean_train), replace = F, size = nrow(clean_train)*0.7)


train1 <- clean_train[train_rows, ]
val1 <- clean_train[-train_rows, ]
```



##Model Building

### Simple LM Model (will follow with StepAIC)
```{r}

lm_mdl <- lm(HomeAssetValue ~ ., train1)
summary(lm_mdl)
par(mfrow=c(2,2))
plot(lm_mdl)
par(mfrow=c(1,1))

```

```{r}
getconstantcols <- function(in_df) {
  constantcols <- colnames(in_df[ ,sapply(in_df, function(v){ var(v, na.rm=TRUE)==0})])
  return(constantcols)
}

getconstantcols(train1)


```



#There's a lot of heteroscadasticity and also the QQ plot shows there's a lot of variance in errors.

```{r}
mdl1_preds <- predict(object = lm_mdl, newdata = val1)

library(DMwR)
regr.eval(mdl1_preds, val1$HomeAssetValue)

mdl1_unseen <- predict(object = lm_mdl, newdata = clean_test)

write.csv(x = mdl1_unseen, file = 'predictions.csv')

```

** This gave a MAPE of 28.68%. However the model summary shows a low value of Rsquared and lot of insignificant variables.
** Will try using StepAIC to reduce the number of variables

```{r}
library(MASS)
aic_options <- stepAIC(object = lm_mdl, direction="both", trace=FALSE)

```


# will use log of HomeAssetValue for predictions



### Lasso 
```{r}

library(glmnet)
set.seed(1234)

cv_lasso <- cv.glmnet(as.matrix(subset(train1, select = -HomeAssetValue)), as.matrix(train1$HomeAssetValue), alpha = 1, type.measure = "deviance", nfolds = 5)
par(mfrow=c(1,2))
plot(cv_lasso)
plot(cv_lasso$glmnet.fit, xvar = 'lambda', label = TRUE)
par(mfrow=c(1,1))

```


* Trying lasso regression with lambda = min
```{r}
cv_lasso$lambda
lasso_1 <- glmnet(x = as.matrix(subset(train1, select = -HomeAssetValue)), y = as.matrix(train1$HomeAssetValue), family = "gaussian", alpha = 1, lambda = cv_lasso$lambda.min)
lasso_1
```

```{r}
lasso1_preds <- predict(object = lasso_1, newx = as.matrix(subset(val1, select = -HomeAssetValue)))
regr.eval(lasso1_preds, val1$HomeAssetValue)
```

#submitting predictions on test data
```{r}
lasso1_test_preds <- predict(object = lasso_1, newx = as.matrix(clean_test))

write.csv(x = lasso1_test_preds, file = 'predictions.csv')


```

** This gave a MAPE of 28.49068%

###trying with lamda of 1se
```{r}

lasso2 <- glmnet(x = as.matrix(subset(train1, select = -HomeAssetValue)), y = as.matrix(train1$HomeAssetValue), family = "gaussian", alpha = 1, lambda = cv_lasso$lambda.1se)
lasso2

```

```{r}
lasso2_preds <- predict(object = lasso2, newx = as.matrix(subset(val1, select = -HomeAssetValue)))
regr.eval(lasso2_preds, val1$HomeAssetValue)

```

```{r}

lasso2_test_preds <- predict(object = lasso2, newx = as.matrix(clean_test))

write.csv(x = lasso2_test_preds, file = 'predictions.csv')

```

**With lambda at 1se, we got a MAPE of 28.66485% on Grader... so not using 1se and keeping min**


###ElasticNEt
```{r}


set.seed(1234)

cv_elast <- cv.glmnet(as.matrix(subset(train1, select = -HomeAssetValue)), as.matrix(train1$HomeAssetValue), alpha = 0.5, type.measure = "deviance", nfolds = 5)
par(mfrow=c(1,2))
plot(cv_elast)
plot(cv_elast$glmnet.fit, xvar = 'lambda', label = TRUE)
par(mfrow=c(1,1))

```


```{r}
elast1 <- glmnet(x = as.matrix(subset(train1, select = -HomeAssetValue)), y = as.matrix(train1$HomeAssetValue), family = "gaussian", alpha = 0.5, lambda = cv_elast$lambda.min)
elast1
```

```{r}
elast1_preds <- predict(object = elast1, newx = as.matrix(subset(val1, select = -HomeAssetValue)))
regr.eval(elast1_preds, val1$HomeAssetValue)
elast1_test_preds <- predict(object = elast1, newx = as.matrix(clean_test))

write.csv(x = elast1_test_preds, file = 'predictions.csv')
```

**Submission on grader got a MAPE of 28.4867%**


**since there are a lot of columns, trying PCA**
```{r}
set.seed(1234)
train_pca <- prcomp(x = train1[,!colnames(train1) %in% 'HomeAssetValue'])

summary(train_pca)
#This shows that first 50 components can account for approximately 94% of variance in the dataset.
# So building an SVM Model with this dataset

pca_viz <- data.frame(Component=colnames(train_pca$x), CumSum=(cumsum(train_pca$sdev^2 / sum(train_pca$sdev^2))*100), PropVariance=(train_pca$sdev^2 / sum(train_pca$sdev^2))*100)
rownames(pca_viz) <- pca_viz$Component
pca_viz$Component <- NULL

head(pca_viz)

write.csv(x = pca_viz, file = 'pcaviz.csv')

ggplot(pca_viz) +
  geom_bar(mapping = aes(x = CumSum))

str(pca_viz)
head(pca_viz)

train_pca_data <- data.frame(train_pca$x[,1:50], HomeAssetValue=train1$HomeAssetValue)
val_pca <- predict(train_pca, newdata = val1)

val_pca <- as.data.frame(val_pca[,1:50])

library(e1071)

svm_mdl <- svm(HomeAssetValue ~ ., data = train_pca_data)

svm_mdl

svm_val_preds <- predict(object = svm_mdl, newdata = val_pca)
library(DMwR)
regr.eval(svm_val_preds, val1$HomeAssetValue)
```

###predicting for svm
```{r}

#first need to get the test_data into pca
test_pca <- predict(object = train_pca, newdata = clean_test)
test_pca <- as.data.frame(test_pca[,1:50])
svm_test_preds <- predict(object = svm_mdl, newdata = test_pca)
write.csv(x = svm_test_preds, file = 'predictions.csv')


```


** This gave a MAPE of 26.55417% on Grader!!!**


###Let's try to use KSVM instead

```{r}
library(kernlab)

ksvm_mdl <- ksvm(HomeAssetValue ~ ., data = train_pca_data, kernel = 'polydot')
ksvm_mdl
```

```{r}
ksvm_val_preds <- predict(object = ksvm_mdl, newdata = val_pca)
regr.eval(ksvm_val_preds, val1$HomeAssetValue)
```



```{r}
ksvm_test_preds <- predict(object = ksvm_mdl, newdata = test_pca)
write.csv(x = ksvm_test_preds, file = 'predictions.csv')


```

** MAPE increased with polydot kernel function to 28.93886%**

####checking if RBF has any better predictions

```{r}
library(kernlab)
train_pca_data <- data.frame(train_pca$x[,1:50], HomeAssetValue=train1$HomeAssetValue)
val_pca <- predict(train_pca, newdata = val1)

val_pca <- as.data.frame(val_pca[,1:50])
test_pca <- predict(object = train_pca, newdata = clean_test)
test_pca <- as.data.frame(test_pca[,1:50])
ksvm_rbf_mdl <- ksvm(HomeAssetValue ~ ., data = train_pca_data, kernel = 'rbfdot')
ksvm_rbf_mdl
```


```{r}

ksvm_rbf_val_preds <- predict(object = ksvm_rbf_mdl, newdata = val_pca)
regr.eval(ksvm_rbf_val_preds, val1$HomeAssetValue)
```


```{r}
ksvm_rbf_test_preds <- predict(object = ksvm_rbf_mdl, newdata = test_pca)
submission <- data.frame(ID=rownames(test_pca), HomeAssetValue=ksvm_rbf_test_preds)
write.csv(x = submission, file = 'predictions.csv', row.names = F)
```

** This got a MAPE of 26.53% on Grader**

####How about increasing the number of components?

```{r}
summary(train_pca)
train_pca_data <- data.frame(train_pca$x[,1:60], HomeAssetValue=train1$HomeAssetValue)
val_pca <- predict(train_pca, newdata = val1)

val_pca <- as.data.frame(val_pca[,1:60])
test_pca <- predict(object = train_pca, newdata = clean_test)
test_pca <- as.data.frame(test_pca[,1:60])

```


#### trying RBF with the expanded set
```{r}
ksvm_rbf_mdl <- ksvm(HomeAssetValue ~ ., data = train_pca_data, kernel = 'rbfdot')
ksvm_rbf_mdl

ksvm_rbf_val_preds <- predict(object = ksvm_rbf_mdl, newdata = val_pca)
regr.eval(ksvm_rbf_val_preds, val1$HomeAssetValue)

ksvm_rbf_test_preds <- predict(object = ksvm_rbf_mdl, newdata = test_pca)
write.csv(x = ksvm_rbf_test_preds, file = 'predictions.csv')
```



###XGBoost maybe?



```{r}
library(xgboost)
params <- list(booster = "gbtree", 
               objective = "reg:linear", 
               eta=0.1, 
               gamma=0,
               lambda=0.5,
               alpha=0,
               max_depth=6, 
               min_child_weight=1, 
               subsample=0.6, 
               colsample_bytree=0.7)

train_matrix <- as.matrix(train_pca_data[,!colnames(train_pca_data) %in% 'HomeAssetValue'])
label = train_pca_data$HomeAssetValue
xgb_mdl <- xgboost(data = train_matrix, label = label, params = params, nrounds = 100, print_every_n = 10)

summary(xgb_mdl)

```


```{r}
xgb_preds <- predict(object = xgb_mdl, newdata = as.matrix(val_pca))

regr.eval(xgb_preds, val1$HomeAssetValue)
```


```{r}
xgb_test_preds <- predict(object = xgb_mdl, newdata = as.matrix(test_pca))

xgb_out <- data.frame(ID=rownames(test_pca), HomeAssetValue=xgb_test_preds)

write.csv(x = xgb_out, file = 'predictions.csv', row.names = F)

```


xgboost with original data

```{r}
library(xgboost)
params <- list(booster = "gbtree", 
               objective = "reg:linear", 
               eta=0.3, 
               max_depth=6, 
               min_child_weight=1, 
               subsample=0.6, 
               colsample_bytree=1)

train_matrix <- as.matrix(clean_train[,!colnames(clean_train) %in% 'HomeAssetValue'])
label = clean_train$HomeAssetValue
xgb_mdl <- xgboost(data = train_matrix, label = label, params = params, nrounds = 100, print_every_n = 10)

summary(xgb_mdl)
```

```{r}
xgb_preds <- predict(object = xgb_mdl, newdata = as.matrix(val1))

regr.eval(xgb_preds, val1$HomeAssetValue)
```


```{r}

xgb_test_preds <- predict(object = xgb_mdl, newdata = as.matrix(clean_test))

xgb_out <- data.frame(ID=rownames(clean_test), HomeAssetValue=xgb_test_preds)

write.csv(x = xgb_out, file = 'predictions.csv', row.names = F)

```

